# LOCALTRIAGE

A self-hosted, privacy-preserving customer support triage platform powered by local LLMs.

[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.11+-green.svg)](https://python.org)

## Overview

LOCALTRIAGE is an end-to-end customer support system that:

- **ğŸ·ï¸ Automatically triages** incoming tickets by category and priority
- **ğŸ“ Drafts responses** using RAG (Retrieval-Augmented Generation) with citations
- **ğŸ“Š Generates insights** to identify emerging product issues
- **ğŸ”’ Runs entirely locally** - no data leaves your infrastructure

## Features

### Intelligent Routing
- TF-IDF + Logistic Regression baseline classifier
- Multi-class categorization (Billing, Technical, Account, etc.)
- Priority prediction (P1-P4)
- Confidence scoring for human escalation

### RAG-Powered Drafting
- Hybrid retrieval (dense + sparse search with RRF fusion)
- Local LLM generation (Qwen2.5-14B or 7B)
- Automatic citation of knowledge base sources
- Confidence indicators for agent review

### Analytics & Insights
- Weekly trend analysis
- Emerging issue detection via topic clustering
- Resolution time tracking
- Performance dashboards

## Quick Start

### Prerequisites
- Docker & Docker Compose
- Python 3.11+
- 32GB+ RAM (64GB recommended)
- GPU with 24GB+ VRAM (optional, for faster inference)

### 1. Clone and Configure

```bash
git clone https://github.com/your-org/localtriage.git
cd localtriage
cp .env.example .env
# Edit .env with your settings
```

### 2. Start Services

```bash
# CPU-only deployment
docker compose --profile cpu up -d

# With GPU (uncomment llm-gpu in docker-compose.yml)
docker compose up -d
```

### 3. Initialize Database

```bash
# Apply schema
docker compose exec api python -m ingestion.setup

# Ingest sample data (optional)
docker compose exec api python -m ingestion.ingest --sample
```

### 4. Access the Dashboard

Open http://localhost:8501 in your browser.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Streamlit UI                         â”‚
â”‚                    (http://localhost:8501)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FastAPI Backend                         â”‚
â”‚                    (http://localhost:8080)                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  Triage  â”‚  â”‚  Drafting â”‚  â”‚ Retrievalâ”‚  â”‚  Analytics â”‚  â”‚
â”‚  â”‚  Router  â”‚  â”‚    RAG    â”‚  â”‚  Hybrid  â”‚  â”‚   Engine   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚             â”‚               â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚  PostgreSQL  â”‚ â”‚   vLLM    â”‚ â”‚   Qdrant  â”‚ â”‚  Embeddings â”‚
â”‚   Database   â”‚ â”‚   /llama  â”‚ â”‚  Vectors  â”‚ â”‚   Service   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check and component status |
| `/triage` | POST | Classify ticket category and priority |
| `/draft` | POST | Generate RAG-based response draft |
| `/similar` | POST | Find similar historical tickets |
| `/feedback` | POST | Submit agent feedback on drafts |
| `/metrics` | GET | Get system performance metrics |
| `/tickets` | GET | List tickets with pagination |

### Example: Generate Draft

```bash
curl -X POST http://localhost:8080/draft \
  -H "Content-Type: application/json" \
  -d '{
    "subject": "Cannot reset password",
    "body": "The reset email never arrived",
    "use_llm": true
  }'
```

## Configuration

Key environment variables:

| Variable | Default | Description |
|----------|---------|-------------|
| `DB_HOST` | localhost | PostgreSQL host |
| `LLM_BASE_URL` | http://localhost:8000/v1 | LLM API endpoint |
| `LLM_MODEL` | Qwen/Qwen2.5-14B-Instruct | Model to use |
| `VECTOR_STORE_TYPE` | qdrant | Vector store (qdrant/faiss) |
| `USE_LLM` | true | Enable LLM drafting |

See [.env.example](.env.example) for full configuration.

## Project Structure

```
localtriage/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/          # FastAPI application
â”‚   â”œâ”€â”€ ingestion/    # Data loading & schema
â”‚   â”œâ”€â”€ retrieval/    # BM25 & vector search
â”‚   â”œâ”€â”€ triage/       # Classification/routing
â”‚   â”œâ”€â”€ rag/          # LLM drafting
â”‚   â”œâ”€â”€ evaluation/   # Metrics & testing
â”‚   â””â”€â”€ ui/           # Streamlit dashboard
â”œâ”€â”€ notebooks/        # Jupyter notebooks
â”œâ”€â”€ docs/             # Documentation
â”œâ”€â”€ infra/            # Docker & monitoring
â”œâ”€â”€ data/             # Data storage
â””â”€â”€ tests/            # Test suite
```

## Evaluation

Run the evaluation harness:

```bash
# Full evaluation
python -m evaluation.eval_harness --mode full

# Quick baseline comparison
python -m evaluation.eval_harness --mode compare
```

### Target Metrics

| Metric | Baseline | Target | Achieved |
|--------|----------|--------|----------|
| Routing Accuracy | 72% | 90% | - |
| Retrieval Recall@5 | 58% | 80% | - |
| Draft Quality (1-5) | 2.1 | 4.0 | - |
| P95 Latency | 8.2s | 5.0s | - |

## Development

### Local Setup

```bash
# Create virtual environment
python -m venv .venv
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Run tests
pytest tests/ -v

# Start development server
uvicorn src.api.api:app --reload --port 8080
```

### Running Notebooks

```bash
jupyter lab --notebook-dir=notebooks
```

## Documentation

- [Business Requirements](docs/BRD.md)
- [Technical Context](docs/CONTEXT.md)
- [Decision Matrix](docs/decision_matrix.md)
- [Project Plan](docs/project_plan.md)
- [Risk Register](docs/risk_register.md)

## License

MIT License - see [LICENSE](LICENSE) for details.

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Run tests and linting
5. Submit a pull request

---

Built with â¤ï¸ for privacy-conscious customer support teams
